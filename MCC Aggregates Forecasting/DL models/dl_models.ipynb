{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yUbMnhEpBxsN","executionInfo":{"status":"ok","timestamp":1748893124750,"user_tz":-180,"elapsed":5757,"user":{"displayName":"V L","userId":"06129047709976680873"}}},"outputs":[],"source":["# Imports\n","import pandas as pd\n","import numpy as np\n","import json\n","import warnings\n","from datetime import datetime\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import lightning.pytorch as pl\n","from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n","from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n","from pytorch_forecasting.data import GroupNormalizer\n","from pytorch_forecasting.metrics import SMAPE, MAE, RMSE\n","\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1u8X13AFBxsO","executionInfo":{"status":"ok","timestamp":1748893126494,"user_tz":-180,"elapsed":1742,"user":{"displayName":"V L","userId":"06129047709976680873"}},"outputId":"abce7cc4-9ae5-4474-8620-f0423f533ca0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Environment: colab\n","Base path: /content/drive/MyDrive/fcst/\n"]}],"source":["# Environment and path setup\n","def detect_environment():\n","    \"\"\"Detect if running in Colab or local environment\"\"\"\n","    try:\n","        import google.colab\n","        from google.colab import drive\n","        drive.mount('/content/drive/')\n","        return 'colab', '/content/drive/MyDrive/fcst/'\n","    except ImportError:\n","        return 'local', '..'\n","\n","environment, base_path = detect_environment()\n","print(f\"Environment: {environment}\")\n","print(f\"Base path: {base_path}\")\n","\n","import sys\n","sys.path.append(base_path+'MCC Aggregates Forecasting/')\n","from evaluation import evaluate_and_report_mcc\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gr0Z8MxHBxsO","executionInfo":{"status":"ok","timestamp":1748893130140,"user_tz":-180,"elapsed":3644,"user":{"displayName":"V L","userId":"06129047709976680873"}},"outputId":"d166bbf5-0ca6-491d-84c2-e6706dbd4cf4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading pre-processed DL features...\n","LSTM data loaded: 159,659 sequences\n","TFT data loaded: 8,461,927 records\n","LSTM - Train: 81,815, Test: 77,844\n"]}],"source":["# Load New DL Features\n","print(\"Loading pre-processed DL features...\")\n","\n","# Load LSTM format data\n","try:\n","    lstm_data = pd.read_parquet(f'{base_path}/data/features/dl_lstm_format.parquet')\n","    print(f\"LSTM data loaded: {len(lstm_data):,} sequences\")\n","except FileNotFoundError:\n","    print(\"ERROR: dl_lstm_format.parquet not found. Run dl_features.py first!\")\n","    raise\n","\n","# Load TFT format data if available\n","try:\n","    tft_data = pd.read_parquet(f'{base_path}/data/features/dl_tft_format.parquet')\n","    print(f\"TFT data loaded: {len(tft_data):,} records\")\n","except FileNotFoundError:\n","    print(\"WARNING: dl_tft_format.parquet not found, TFT will be skipped\")\n","    tft_data = None\n","\n","# Split train/test\n","lstm_train = lstm_data[lstm_data['split'] == 'train'].copy()\n","lstm_test = lstm_data[lstm_data['split'] == 'test'].copy()\n","\n","print(f\"LSTM - Train: {len(lstm_train):,}, Test: {len(lstm_test):,}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWGcL_oyBxsO","executionInfo":{"status":"ok","timestamp":1748893147898,"user_tz":-180,"elapsed":17759,"user":{"displayName":"V L","userId":"06129047709976680873"}},"outputId":"544087ac-8073-4f42-a24f-6e169c62d713"},"outputs":[{"output_type":"stream","name":"stdout","text":["LSTM tensors - Train: torch.Size([81815, 52, 2]), Test: torch.Size([77844, 52, 2])\n"]}],"source":["# Prepare LSTM Data\n","def prepare_lstm_tensors(data):\n","    \"\"\"Convert LSTM format data to tensors\"\"\"\n","    sequences = []\n","    targets = []\n","\n","    for _, row in data.iterrows():\n","        # Convert sequence list to numpy array\n","        seq_array = np.array(row['sequence'])  # Shape: (52, 2) - simplified to amount & month\n","        sequences.append(seq_array)\n","        targets.append(row['target'])\n","\n","    return torch.FloatTensor(sequences), torch.FloatTensor(targets)\n","\n","# Create LSTM tensors\n","X_train, y_train = prepare_lstm_tensors(lstm_train)\n","X_test, y_test = prepare_lstm_tensors(lstm_test)\n","\n","print(f\"LSTM tensors - Train: {X_train.shape}, Test: {X_test.shape}\")\n","\n","# Create dataloaders\n","train_dataset = TensorDataset(X_train, y_train)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","# SPEED OPTIMIZATION: Larger batch sizes for faster training\n","train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["15385915c8584449b34f429ebfa53909","02a04caed552476d9474ed237f1e9598","2ccd970e9539478e8b8cfca56fe164ff","fb4add33dfd546fe9b11cdef05264703","7fbf57d36d314bba97d7f47f4772edf9","ea39cbc5fc014c4d91d32a19688fbf05","841c8657f2904855af9bd74c47fa1500","2057c4a54a8f464b96fb3c1fb0019c2c","4a9be33a667f40da990d65b3cdd15ac5","2da8da047d524ceba067ed00235b4319","3da277fa276e47eba12a48b250efea2a","ee2e5375f7bb483ca5f00b0aa0dc0721","0526dcf9dc544979a35b5c93bc8687b9","a597f55d138d47ffaa6273293ed1700d","3522ffbc58ee435caaf46c34e6eb1e5c","4ceb821cdef040ecb3a15f2fa1869847","dccf9d017c674a67ae635487ff190a92","9f15ca3618404a87a4237d5a6d8cd2e4","26f34bd134914a489dd35c5fa575ef35","a9b268545639477186db0bb28cb34d56","c6abe3c394f84252a0513f117ea3272e","e6495086affe4edb9d2439ccfab6bc80","53df4762abb0485aadb3b09de3a5d7ef","c2ce0824f99444db9660745943ad9bb7","e650e0f37a934757ac9d876bba30de69","3ce4f7bf753a4c7e82b06b4763aca44a","0fd3e7f67c3f4100b46f3decfd207f69","d9f3fae96546489ba8d398dba48ea74f","31a81719464f4b608ec0a7b0b4d2abc9","4d9c26357c10442f946047902636078b","bc7ce8b2b3d942c085c1bc5fc1573c38","8da78f4603c24955a04f6473d3cce7aa","b55f310ea67945d4af7f08fd9fe7379e","a8ceebf0bfa346df8f69ae3a3b7353b1","47cb0146016c4bf5a76a2eb91e574663","be7d31ab4a494d459bf437e3cb460852","c0e4f516d29e40b2b6019a5568c93941","a3fc6ede35194bc2ae0727e741f062e9","b1f0064c0d33471db85d93efd4ff6afe","e4fcceccf52c4855bcf72b90a9452757","5bbc322e566d464a88abdbb96a02ac7a","55d0489c1b934ceb814ccd09ee0a1b43","7b4489d72ec8457cb6a8430ee78e1c3d","bd50eb3c39404fbca09451c427755728"]},"id":"Biz858IPBxsP","executionInfo":{"status":"ok","timestamp":1748894071859,"user_tz":-180,"elapsed":923374,"user":{"displayName":"V L","userId":"06129047709976680873"}},"outputId":"9fd3da2d-fee6-41ee-95c5-5b4fe41a44f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","TRAINING TEMPORAL FUSION TRANSFORMER (PRIMARY DL MODEL)\n","==================================================\n","TFT train: 4,336,195, test: 4,125,732\n","TFT data columns: ['series_id', 'time_idx', 'split', 'amount', 'month', 'yearly_income', 'total_debt', 'credit_score', 'current_age', 'target', 'training_cutoff']\n","Target records (time_idx=52): 159659\n","Target values sample: 52     221.570007\n","105    264.320007\n","158    709.369995\n","211    974.809998\n","264    416.429993\n","Name: target, dtype: float64\n","Target values stats: min=0.0200, max=5177.7598, mean=232.4865\n","Before processing: 8461927 records\n","After processing: 8461927 records\n","Set amount=0 for target timesteps to prevent data leakage\n","Available features: ['series_id', 'time_idx', 'split', 'amount', 'month', 'yearly_income', 'total_debt', 'credit_score', 'current_age', 'target', 'training_cutoff']\n","Using time_varying_known: ['time_idx', 'month']\n","Using time_varying_unknown: ['amount']\n","Using static_reals: ['yearly_income', 'total_debt', 'credit_score', 'current_age']\n","SPEED OPTIMIZATION: Sampled 100 series from 4072 total\n","Filtered to 100 series with >= 30 timesteps\n","Train data shape: (120734, 12)\n","Unique series in train: 100\n","Training subset: 95676 samples\n","Validation subset: 25058 samples\n","TFT Training samples: 150126\n","TFT Validation samples: 100\n","Error getting sample batch: 0\n","TFT model created successfully\n"]},{"output_type":"stream","name":"stderr","text":["INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","INFO:lightning.pytorch.utilities.rank_zero:You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["Starting TFT training...\n"]},{"output_type":"stream","name":"stderr","text":["INFO: \n","   | Name                               | Type                            | Params | Mode \n","------------------------------------------------------------------------------------------------\n","0  | loss                               | QuantileLoss                    | 0      | train\n","1  | logging_metrics                    | ModuleList                      | 0      | train\n","2  | input_embeddings                   | MultiEmbedding                  | 0      | train\n","3  | prescalers                         | ModuleDict                      | 88     | train\n","4  | static_variable_selection          | VariableSelectionNetwork        | 1.6 K  | train\n","5  | encoder_variable_selection         | VariableSelectionNetwork        | 852    | train\n","6  | decoder_variable_selection         | VariableSelectionNetwork        | 618    | train\n","7  | static_context_variable_selection  | GatedResidualNetwork            | 304    | train\n","8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 304    | train\n","9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 304    | train\n","10 | static_context_enrichment          | GatedResidualNetwork            | 304    | train\n","11 | lstm_encoder                       | LSTM                            | 576    | train\n","12 | lstm_decoder                       | LSTM                            | 576    | train\n","13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 144    | train\n","14 | post_lstm_add_norm_encoder         | AddNorm                         | 16     | train\n","15 | static_enrichment                  | GatedResidualNetwork            | 368    | train\n","16 | multihead_attn                     | InterpretableMultiHeadAttention | 280    | train\n","17 | post_attn_gate_norm                | GateAddNorm                     | 160    | train\n","18 | pos_wise_ff                        | GatedResidualNetwork            | 304    | train\n","19 | pre_output_gate_norm               | GateAddNorm                     | 160    | train\n","20 | output_layer                       | Linear                          | 63     | train\n","------------------------------------------------------------------------------------------------\n","6.9 K     Trainable params\n","0         Non-trainable params\n","6.9 K     Total params\n","0.028     Total estimated model params size (MB)\n","362       Modules in train mode\n","0         Modules in eval mode\n","INFO:lightning.pytorch.callbacks.model_summary:\n","   | Name                               | Type                            | Params | Mode \n","------------------------------------------------------------------------------------------------\n","0  | loss                               | QuantileLoss                    | 0      | train\n","1  | logging_metrics                    | ModuleList                      | 0      | train\n","2  | input_embeddings                   | MultiEmbedding                  | 0      | train\n","3  | prescalers                         | ModuleDict                      | 88     | train\n","4  | static_variable_selection          | VariableSelectionNetwork        | 1.6 K  | train\n","5  | encoder_variable_selection         | VariableSelectionNetwork        | 852    | train\n","6  | decoder_variable_selection         | VariableSelectionNetwork        | 618    | train\n","7  | static_context_variable_selection  | GatedResidualNetwork            | 304    | train\n","8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 304    | train\n","9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 304    | train\n","10 | static_context_enrichment          | GatedResidualNetwork            | 304    | train\n","11 | lstm_encoder                       | LSTM                            | 576    | train\n","12 | lstm_decoder                       | LSTM                            | 576    | train\n","13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 144    | train\n","14 | post_lstm_add_norm_encoder         | AddNorm                         | 16     | train\n","15 | static_enrichment                  | GatedResidualNetwork            | 368    | train\n","16 | multihead_attn                     | InterpretableMultiHeadAttention | 280    | train\n","17 | post_attn_gate_norm                | GateAddNorm                     | 160    | train\n","18 | pos_wise_ff                        | GatedResidualNetwork            | 304    | train\n","19 | pre_output_gate_norm               | GateAddNorm                     | 160    | train\n","20 | output_layer                       | Linear                          | 63     | train\n","------------------------------------------------------------------------------------------------\n","6.9 K     Trainable params\n","0         Non-trainable params\n","6.9 K     Total params\n","0.028     Total estimated model params size (MB)\n","362       Modules in train mode\n","0         Modules in eval mode\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15385915c8584449b34f429ebfa53909"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee2e5375f7bb483ca5f00b0aa0dc0721"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53df4762abb0485aadb3b09de3a5d7ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: |          | 0/? [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8ceebf0bfa346df8f69ae3a3b7353b1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n","INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Generating TFT predictions on test data...\n"]},{"output_type":"stream","name":"stderr","text":["INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n","INFO:lightning.pytorch.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n","INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["SPEED OPTIMIZATION: Using test data from same 100 series as training\n","Test data filtered to 96937 records from original test set\n","Further sampled to 50 series for speed\n","Test dataset size: 50\n","Predictions shape: (50,)\n","Actuals shape: (50,)\n","\n","============================================================\n","MCC AGGREGATES FORECASTING REPORT: TFT (PRIMARY DL MODEL)\n","============================================================\n","\n","OVERALL PERFORMANCE:\n","Metric          Value          \n","------------------------------\n","sMAPE_w         200.0000       \n","RMSSE_w         3.3882         \n","MAE             747.6486       \n","RMSE            809.0996       \n","\n","============================================================\n","\n"]}],"source":["# Temporal Fusion Transformer (Primary DL Model)\n","if tft_data is not None:\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"TRAINING TEMPORAL FUSION TRANSFORMER (PRIMARY DL MODEL)\")\n","    print(\"=\"*50)\n","\n","    try:\n","        # Prepare TFT data\n","        tft_train = tft_data[tft_data['split'] == 'train'].copy()\n","        tft_test = tft_data[tft_data['split'] == 'test'].copy()\n","\n","        print(f\"TFT train: {len(tft_train):,}, test: {len(tft_test):,}\")\n","\n","        # Create training cutoff based on time_idx\n","        max_time_idx = tft_train.groupby('series_id')['time_idx'].max()\n","        training_cutoff = (max_time_idx * 0.8).astype(int).to_dict()\n","\n","        tft_combined = pd.concat([tft_train, tft_test], ignore_index=True)\n","        tft_combined['training_cutoff'] = tft_combined['series_id'].map(training_cutoff)\n","\n","        # Check if target column exists and has values at time_idx=52\n","        print(f\"TFT data columns: {tft_combined.columns.tolist()}\")\n","        target_records = tft_combined[tft_combined['time_idx'] == 52]\n","        print(f\"Target records (time_idx=52): {len(target_records)}\")\n","        if len(target_records) > 0:\n","            print(f\"Target values sample: {target_records['target'].head()}\")\n","            print(f\"Target values stats: min={target_records['target'].min():.4f}, max={target_records['target'].max():.4f}, mean={target_records['target'].mean():.4f}\")\n","\n","        # PREVENT DATA LEAKAGE: Remove amount from target timestep (time_idx=52)\n","        if 'amount' in tft_combined.columns:\n","            # For target timesteps (time_idx=52), remove amount to prevent data leakage\n","            # For historical timesteps (time_idx<52), keep amount and set target=0\n","            print(f\"Before processing: {len(tft_combined)} records\")\n","\n","            # Fill target=0 for historical timesteps (time_idx < 52)\n","            tft_combined.loc[tft_combined['time_idx'] < 52, 'target'] = 0\n","\n","            # For target timesteps (time_idx=52), remove amount column value\n","            tft_combined.loc[tft_combined['time_idx'] == 52, 'amount'] = 0\n","\n","            print(f\"After processing: {len(tft_combined)} records\")\n","            print(f\"Set amount=0 for target timesteps to prevent data leakage\")\n","\n","        # Check for any remaining NaN values in amount\n","        if 'amount' in tft_combined.columns:\n","            nan_count = tft_combined['amount'].isna().sum()\n","            if nan_count > 0:\n","                print(f\"Warning: {nan_count} NaN values found in amount, filling with 0\")\n","                tft_combined['amount'] = tft_combined['amount'].fillna(0)\n","\n","        # Check available features\n","        available_features = tft_combined.columns.tolist()\n","        print(f\"Available features: {available_features}\")\n","\n","        # Use only available features (NO DATA LEAKAGE)\n","        time_varying_known = ['time_idx']\n","        time_varying_unknown = []\n","        static_reals = []\n","\n","        # Add time features\n","        if 'month' in available_features:\n","            time_varying_known.append('month')\n","\n","        # Add historical amount data (OK since it's historical, not current)\n","        if 'amount' in available_features:\n","            time_varying_unknown.append('amount')\n","\n","        # Add static features if available\n","        static_features = ['yearly_income', 'total_debt', 'credit_score', 'current_age']\n","        for feat in static_features:\n","            if feat in available_features:\n","                static_reals.append(feat)\n","\n","        print(f\"Using time_varying_known: {time_varying_known}\")\n","        print(f\"Using time_varying_unknown: {time_varying_unknown}\")\n","        print(f\"Using static_reals: {static_reals}\")\n","\n","        # Use simpler train/validation split to avoid unknown categories\n","        # Instead of complex cutoff, use simple time-based split\n","        train_data = tft_combined[tft_combined['split'] == 'train'].copy()\n","\n","        # SPEED OPTIMIZATION: Sample only a small subset for fast training\n","        unique_series = train_data['series_id'].unique()\n","\n","        # Sample only 100 series for fast training (instead of 4000+)\n","        np.random.seed(42)  # For reproducibility\n","        sampled_series = np.random.choice(unique_series, size=min(100, len(unique_series)), replace=False)\n","        train_data = train_data[train_data['series_id'].isin(sampled_series)].copy()\n","\n","        print(f\"SPEED OPTIMIZATION: Sampled {len(sampled_series)} series from {len(unique_series)} total\")\n","\n","        # Ensure we have enough data for each series\n","        series_lengths = train_data.groupby('series_id')['time_idx'].count()\n","        valid_series = series_lengths[series_lengths >= 15].index\n","        train_data = train_data[train_data['series_id'].isin(valid_series)].copy()\n","\n","        print(f\"Filtered to {len(valid_series)} series with >= 30 timesteps\")\n","\n","        # For validation, use last 20% of timesteps for each series\n","        max_train_time = train_data.groupby('series_id')['time_idx'].max()\n","        min_train_time = train_data.groupby('series_id')['time_idx'].min()\n","\n","        # Calculate validation cutoff as 80% between min and max for each series\n","        val_cutoff = (min_train_time + (max_train_time - min_train_time) * 0.8).astype(int).to_dict()\n","\n","        train_data['val_cutoff'] = train_data['series_id'].map(val_cutoff)\n","\n","        print(f\"Train data shape: {train_data.shape}\")\n","        print(f\"Unique series in train: {len(train_data['series_id'].unique())}\")\n","\n","        # Debug validation split\n","        train_subset = train_data[train_data['time_idx'] <= train_data['val_cutoff']]\n","        val_subset = train_data[train_data['time_idx'] > train_data['val_cutoff']]\n","        print(f\"Training subset: {len(train_subset)} samples\")\n","        print(f\"Validation subset: {len(val_subset)} samples\")\n","\n","        # TFT Dataset\n","        training_tft = TimeSeriesDataSet(\n","            train_data[train_data['time_idx'] <= train_data['val_cutoff']],\n","            time_idx=\"time_idx\",\n","            target=\"target\",\n","            group_ids=[\"series_id\"],\n","            min_encoder_length=8,\n","            max_encoder_length=16,\n","            min_prediction_length=1,\n","            max_prediction_length=1,\n","            time_varying_known_reals=time_varying_known,\n","            time_varying_unknown_reals=time_varying_unknown,\n","            static_reals=static_reals,\n","            target_normalizer=GroupNormalizer(groups=[\"series_id\"], transformation=\"softplus\"),\n","            add_relative_time_idx=True,\n","            add_target_scales=True,\n","            add_encoder_length=True,\n","            allow_missing_timesteps=True,\n","        )\n","\n","        # Validation uses same series but later time points\n","        validation_tft = TimeSeriesDataSet.from_dataset(\n","            training_tft,\n","            train_data,  # Use same training data to avoid unknown categories\n","            predict=True,\n","            stop_randomization=True\n","        )\n","\n","        # SPEED OPTIMIZATION: Much larger batch sizes\n","        train_dataloader_tft = training_tft.to_dataloader(train=True, batch_size=128, num_workers=0)  # Increased from 32\n","        val_dataloader_tft = validation_tft.to_dataloader(train=False, batch_size=128, num_workers=0)  # Increased from 32\n","\n","        print(f\"TFT Training samples: {len(training_tft)}\")\n","        print(f\"TFT Validation samples: {len(validation_tft)}\")\n","\n","        # Debug: Check a sample batch\n","        try:\n","            sample_batch = next(iter(train_dataloader_tft))\n","            print(f\"Sample batch input shape: {sample_batch[0][0].shape}\")\n","            print(f\"Sample batch target shape: {sample_batch[1].shape}\")\n","        except Exception as e:\n","            print(f\"Error getting sample batch: {e}\")\n","\n","        # Create TFT model\n","        tft = TemporalFusionTransformer.from_dataset(\n","            training_tft,\n","            learning_rate=0.05,  # Increased for faster convergence\n","            hidden_size=8,      # Further reduced for speed\n","            attention_head_size=1,  # Minimal attention heads\n","            dropout=0.0,         # Remove dropout for speed\n","            hidden_continuous_size=4,  # Much smaller\n","            reduce_on_plateau_patience=1,  # Faster patience\n","        )\n","\n","        print(f\"TFT model created successfully\")\n","\n","        # Setup trainer for TFT\n","        trainer_tft = pl.Trainer(\n","            max_epochs=2,  # Only 2 epochs as requested\n","            enable_progress_bar=True,  # Enable progress bar to see training\n","            logger=False,\n","            enable_checkpointing=False,\n","            accelerator=\"gpu\",  # Force GPU\n","            devices=1,\n","            # precision=16,  # Mixed precision for speed\n","        )\n","\n","        print(\"Starting TFT training...\")\n","        # Train TFT\n","        trainer_tft.fit(tft, train_dataloaders=train_dataloader_tft, val_dataloaders=val_dataloader_tft)\n","\n","        # Evaluate TFT on actual test data\n","        print(\"\\nGenerating TFT predictions on test data...\")\n","\n","        # Prepare test data for prediction\n","        test_data = tft_combined[tft_combined['split'] == 'test'].copy()\n","\n","        # SPEED OPTIMIZATION: Sample smaller test set for faster evaluation\n","        train_series_ids = train_data['series_id'].unique()\n","        test_data = test_data[test_data['series_id'].isin(train_series_ids)].copy()\n","\n","        print(f\"SPEED OPTIMIZATION: Using test data from same {len(train_series_ids)} series as training\")\n","        print(f\"Test data filtered to {len(test_data)} records from original test set\")\n","\n","        # Further sample if still too many records for speed\n","        available_test_series = test_data['series_id'].unique()\n","        if len(available_test_series) > 50:\n","            sampled_test_series = np.random.choice(available_test_series, size=50, replace=False)\n","            test_data = test_data[test_data['series_id'].isin(sampled_test_series)].copy()\n","            print(f\"Further sampled to {len(sampled_test_series)} series for speed\")\n","\n","        # Create test dataset from training dataset structure\n","        test_tft = TimeSeriesDataSet.from_dataset(\n","            training_tft,\n","            test_data,\n","            predict=True,\n","            stop_randomization=True\n","        )\n","\n","        test_dataloader_tft = test_tft.to_dataloader(train=False, batch_size=128, num_workers=0)  # Large batch for speed\n","\n","        print(f\"Test dataset size: {len(test_tft)}\")\n","\n","        # Generate predictions\n","        tft_predictions = tft.predict(test_dataloader_tft, trainer_kwargs=dict(logger=False))\n","\n","        if hasattr(tft_predictions, 'cpu'):\n","            y_pred_tft = tft_predictions.cpu().numpy().flatten()\n","        else:\n","            y_pred_tft = tft_predictions.flatten()\n","\n","        # Get actual test targets (from original test data)\n","        test_targets = test_data[test_data['time_idx'] == 52]['target'].values\n","        y_true_tft = test_targets[:len(y_pred_tft)]  # Match prediction length\n","\n","        print(f\"Predictions shape: {y_pred_tft.shape}\")\n","        print(f\"Actuals shape: {y_true_tft.shape}\")\n","\n","        # Get training data for RMSSE calculation - use actual target values from training set\n","        train_target_mask = (train_data['time_idx'] == 52)\n","        train_amounts = train_data.loc[train_target_mask, 'target'].values\n","\n","        # Evaluate TFT\n","        tft_metrics, tft_report = evaluate_and_report_mcc(\n","            \"TFT (Primary DL Model)\", y_true_tft, y_pred_tft, train_amounts, print_report=True\n","        )\n","        tft_success = True\n","\n","    except Exception as e:\n","        import traceback\n","        print(f\"TFT training/evaluation failed: {str(e)}\")\n","        print(f\"Error type: {type(e).__name__}\")\n","        print(\"Full traceback:\")\n","        traceback.print_exc()\n","        tft_metrics = {'sMAPE_w': np.nan, 'RMSSE_w': np.nan, 'MAE': np.nan, 'RMSE': np.nan}\n","        tft_success = False\n","\n","else:\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"TFT DATA MISSING - SKIPPING TFT\")\n","    print(\"=\"*50)\n","    tft_metrics = {'sMAPE_w': np.nan, 'RMSSE_w': np.nan, 'MAE': np.nan, 'RMSE': np.nan}\n","    tft_success = False\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0O3bbpuBxsP","executionInfo":{"status":"ok","timestamp":1748894088619,"user_tz":-180,"elapsed":16757,"user":{"displayName":"V L","userId":"06129047709976680873"}},"outputId":"36de9e43-45e3-4be8-d4a8-cdcccf606151"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","TRAINING ENHANCED LSTM MODEL (PRIMARY DL MODEL)\n","==================================================\n","Using device: cuda\n","Epoch [1/10], Loss: 128278.7498\n","Epoch [2/10], Loss: 93916.9519\n","Epoch [3/10], Loss: 93024.9567\n","Epoch [4/10], Loss: 93095.0072\n","Epoch [5/10], Loss: 90460.9373\n","Epoch [6/10], Loss: 59274.9551\n","Epoch [7/10], Loss: 42654.7646\n","Epoch [8/10], Loss: 37294.5955\n","Epoch [9/10], Loss: 34333.4263\n","Epoch [10/10], Loss: 33232.4935\n","\n","============================================================\n","MCC AGGREGATES FORECASTING REPORT: ENHANCED LSTM (PRIMARY DL MODEL)\n","============================================================\n","\n","OVERALL PERFORMANCE:\n","Metric          Value          \n","------------------------------\n","sMAPE_w         66.8325        \n","RMSSE_w         0.6871         \n","MAE             109.9301       \n","RMSE            171.1378       \n","\n","============================================================\n","\n"]}],"source":["# Enhanced LSTM Model (Primary Deep Learning Model)\n","class EnhancedLSTM(nn.Module):\n","    def __init__(self, input_size=2, hidden_size=64, num_layers=2, output_size=1):\n","        super(EnhancedLSTM, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.1)\n","        self.fc = nn.Sequential(\n","            nn.Linear(hidden_size, hidden_size // 2),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(hidden_size // 2, output_size)\n","        )\n","\n","    def forward(self, x):\n","        lstm_out, _ = self.lstm(x)\n","        last_hidden = lstm_out[:, -1, :]\n","        output = self.fc(last_hidden)\n","        return output\n","\n","# Create and train LSTM model\n","print(\"\\n\" + \"=\"*50)\n","print(\"TRAINING ENHANCED LSTM MODEL (PRIMARY DL MODEL)\")\n","print(\"=\"*50)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","lstm_model = EnhancedLSTM(input_size=2).to(device)  # 2 features per timestep (amount, month)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n","\n","# Training loop\n","epochs = 10  # Optimized for speed\n","for epoch in range(epochs):\n","    lstm_model.train()\n","    train_loss = 0\n","    for batch_X, batch_y in train_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = lstm_model(batch_X)\n","        loss = criterion(outputs.squeeze(), batch_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(train_loader):.4f}\")\n","\n","# Evaluate LSTM\n","lstm_model.eval()\n","lstm_predictions = []\n","lstm_actuals = []\n","\n","with torch.no_grad():\n","    for batch_X, batch_y in test_loader:\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        outputs = lstm_model(batch_X)\n","        lstm_predictions.extend(outputs.squeeze().cpu().numpy())\n","        lstm_actuals.extend(batch_y.cpu().numpy())\n","\n","lstm_predictions = np.array(lstm_predictions)\n","lstm_actuals = np.array(lstm_actuals)\n","\n","# Evaluate LSTM\n","lstm_metrics, lstm_report = evaluate_and_report_mcc(\n","    \"Enhanced LSTM (Primary DL Model)\", lstm_actuals, lstm_predictions, y_train.numpy(), print_report=True\n",")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIiwKyVwBxsQ","executionInfo":{"status":"ok","timestamp":1748894088692,"user_tz":-180,"elapsed":64,"user":{"displayName":"V L","userId":"06129047709976680873"}},"outputId":"103efb50-df5a-44b9-e8f1-5a5e476185c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","FINAL MODEL COMPARISON - ALL DEEP LEARNING MODELS\n","==================================================\n","                              Model   sMAPE_w  RMSSE_w       MAE      RMSE\n","0            TFT (Primary DL Model)  200.0000   3.3882  747.6486  809.0996\n","1  Enhanced LSTM (Primary DL Model)   66.8325   0.6871  109.9301  171.1378\n","\n","Best overall model by sMAPE_w: Enhanced LSTM (Primary DL Model)\n"]}],"source":["# Final Model Comparison\n","print(\"\\n\" + \"=\"*50)\n","print(\"FINAL MODEL COMPARISON - ALL DEEP LEARNING MODELS\")\n","print(\"=\"*50)\n","\n","# Collect all models and their metrics\n","all_models = ['TFT (Primary DL Model)', 'Enhanced LSTM (Primary DL Model)']\n","all_metrics = [tft_metrics, lstm_metrics]\n","\n","# Create comprehensive comparison\n","final_comparison_df = pd.DataFrame({\n","    'Model': all_models,\n","    'sMAPE_w': [m['sMAPE_w'] for m in all_metrics],\n","    'RMSSE_w': [m['RMSSE_w'] for m in all_metrics],\n","    'MAE': [m['MAE'] for m in all_metrics],\n","    'RMSE': [m['RMSE'] for m in all_metrics]\n","})\n","\n","print(final_comparison_df.round(4))\n","\n","# Find best model overall\n","best_model_idx = final_comparison_df['sMAPE_w'].idxmin()\n","best_model = final_comparison_df.loc[best_model_idx, 'Model']\n","print(f\"\\nBest overall model by sMAPE_w: {best_model}\")\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO8epT1tBxsQ","executionInfo":{"status":"ok","timestamp":1748894088714,"user_tz":-180,"elapsed":17,"user":{"displayName":"V L","userId":"06129047709976680873"}},"outputId":"32f64649-c46f-4648-d473-87ed63b522d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final results saved to dl_models_results.json\n","Deep learning models training completed!\n"]}],"source":["# Save Final Results\n","# Convert numpy types to Python types for JSON serialization\n","def convert_to_json_serializable(obj):\n","    \"\"\"Convert numpy types to Python types for JSON serialization\"\"\"\n","    if isinstance(obj, np.floating):\n","        return float(obj)\n","    elif isinstance(obj, np.integer):\n","        return int(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    elif isinstance(obj, dict):\n","        return {k: convert_to_json_serializable(v) for k, v in obj.items()}\n","    elif isinstance(obj, list):\n","        return [convert_to_json_serializable(v) for v in obj]\n","    else:\n","        return obj\n","\n","# Convert metrics to ensure JSON serialization\n","tft_metrics_clean = convert_to_json_serializable(tft_metrics)\n","lstm_metrics_clean = convert_to_json_serializable(lstm_metrics)\n","\n","final_results = {\n","    'experiment_info': {\n","        'timestamp': datetime.now().isoformat(),\n","        'lstm_sequences_train': len(lstm_train),\n","        'lstm_sequences_test': len(lstm_test),\n","        'sequence_length': 52,\n","        'forecast_horizon': 1,\n","        'features_per_timestep': 2,\n","        'device': str(device),\n","        'tft_success': tft_success if 'tft_success' in locals() else False\n","    },\n","    'models': {\n","        'tft_primary_dl_model': {\n","            'metrics': tft_metrics_clean,\n","            'hyperparameters': {\n","                'learning_rate': 0.03,\n","                'hidden_size': 16,\n","                'attention_head_size': 1,\n","                'dropout': 0.0,\n","                'hidden_continuous_size': 8,\n","                'reduce_on_plateau_patience': 1,\n","                'max_epochs': 2\n","            }\n","        },\n","        'enhanced_lstm_primary_dl_model': {\n","            'metrics': lstm_metrics_clean,\n","            'hyperparameters': {\n","                'input_size': 2,\n","                'hidden_size': 64,\n","                'num_layers': 2,\n","                'learning_rate': 0.001,\n","                'epochs': epochs\n","            }\n","        }\n","    },\n","    'comparison': convert_to_json_serializable(final_comparison_df.to_dict('records')),\n","    'best_model': best_model\n","}\n","\n","# Save to JSON\n","with open('dl_models_results.json', 'w') as f:\n","    json.dump(final_results, f, indent=2)\n","\n","print(f\"\\nFinal results saved to dl_models_results.json\")\n","print(\"Deep learning models training completed!\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"15385915c8584449b34f429ebfa53909":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02a04caed552476d9474ed237f1e9598","IPY_MODEL_2ccd970e9539478e8b8cfca56fe164ff","IPY_MODEL_fb4add33dfd546fe9b11cdef05264703"],"layout":"IPY_MODEL_7fbf57d36d314bba97d7f47f4772edf9"}},"02a04caed552476d9474ed237f1e9598":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea39cbc5fc014c4d91d32a19688fbf05","placeholder":"​","style":"IPY_MODEL_841c8657f2904855af9bd74c47fa1500","value":"Sanity Checking DataLoader 0: 100%"}},"2ccd970e9539478e8b8cfca56fe164ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2057c4a54a8f464b96fb3c1fb0019c2c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a9be33a667f40da990d65b3cdd15ac5","value":1}},"fb4add33dfd546fe9b11cdef05264703":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2da8da047d524ceba067ed00235b4319","placeholder":"​","style":"IPY_MODEL_3da277fa276e47eba12a48b250efea2a","value":" 1/1 [00:00&lt;00:00,  1.95it/s]"}},"7fbf57d36d314bba97d7f47f4772edf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"ea39cbc5fc014c4d91d32a19688fbf05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"841c8657f2904855af9bd74c47fa1500":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2057c4a54a8f464b96fb3c1fb0019c2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a9be33a667f40da990d65b3cdd15ac5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2da8da047d524ceba067ed00235b4319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3da277fa276e47eba12a48b250efea2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee2e5375f7bb483ca5f00b0aa0dc0721":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0526dcf9dc544979a35b5c93bc8687b9","IPY_MODEL_a597f55d138d47ffaa6273293ed1700d","IPY_MODEL_3522ffbc58ee435caaf46c34e6eb1e5c"],"layout":"IPY_MODEL_4ceb821cdef040ecb3a15f2fa1869847"}},"0526dcf9dc544979a35b5c93bc8687b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dccf9d017c674a67ae635487ff190a92","placeholder":"​","style":"IPY_MODEL_9f15ca3618404a87a4237d5a6d8cd2e4","value":"Epoch 1: 100%"}},"a597f55d138d47ffaa6273293ed1700d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26f34bd134914a489dd35c5fa575ef35","max":1172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9b268545639477186db0bb28cb34d56","value":1172}},"3522ffbc58ee435caaf46c34e6eb1e5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6abe3c394f84252a0513f117ea3272e","placeholder":"​","style":"IPY_MODEL_e6495086affe4edb9d2439ccfab6bc80","value":" 1172/1172 [07:36&lt;00:00,  2.57it/s, train_loss_step=2.22e-16, val_loss=251.0, train_loss_epoch=2.22e-16]"}},"4ceb821cdef040ecb3a15f2fa1869847":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"dccf9d017c674a67ae635487ff190a92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f15ca3618404a87a4237d5a6d8cd2e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26f34bd134914a489dd35c5fa575ef35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9b268545639477186db0bb28cb34d56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6abe3c394f84252a0513f117ea3272e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6495086affe4edb9d2439ccfab6bc80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53df4762abb0485aadb3b09de3a5d7ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2ce0824f99444db9660745943ad9bb7","IPY_MODEL_e650e0f37a934757ac9d876bba30de69","IPY_MODEL_3ce4f7bf753a4c7e82b06b4763aca44a"],"layout":"IPY_MODEL_0fd3e7f67c3f4100b46f3decfd207f69"}},"c2ce0824f99444db9660745943ad9bb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9f3fae96546489ba8d398dba48ea74f","placeholder":"​","style":"IPY_MODEL_31a81719464f4b608ec0a7b0b4d2abc9","value":"Validation DataLoader 0: 100%"}},"e650e0f37a934757ac9d876bba30de69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d9c26357c10442f946047902636078b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc7ce8b2b3d942c085c1bc5fc1573c38","value":1}},"3ce4f7bf753a4c7e82b06b4763aca44a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8da78f4603c24955a04f6473d3cce7aa","placeholder":"​","style":"IPY_MODEL_b55f310ea67945d4af7f08fd9fe7379e","value":" 1/1 [00:00&lt;00:00,  8.18it/s]"}},"0fd3e7f67c3f4100b46f3decfd207f69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"d9f3fae96546489ba8d398dba48ea74f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31a81719464f4b608ec0a7b0b4d2abc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d9c26357c10442f946047902636078b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc7ce8b2b3d942c085c1bc5fc1573c38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8da78f4603c24955a04f6473d3cce7aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b55f310ea67945d4af7f08fd9fe7379e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8ceebf0bfa346df8f69ae3a3b7353b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47cb0146016c4bf5a76a2eb91e574663","IPY_MODEL_be7d31ab4a494d459bf437e3cb460852","IPY_MODEL_c0e4f516d29e40b2b6019a5568c93941"],"layout":"IPY_MODEL_a3fc6ede35194bc2ae0727e741f062e9"}},"47cb0146016c4bf5a76a2eb91e574663":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1f0064c0d33471db85d93efd4ff6afe","placeholder":"​","style":"IPY_MODEL_e4fcceccf52c4855bcf72b90a9452757","value":"Validation DataLoader 0: 100%"}},"be7d31ab4a494d459bf437e3cb460852":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bbc322e566d464a88abdbb96a02ac7a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55d0489c1b934ceb814ccd09ee0a1b43","value":1}},"c0e4f516d29e40b2b6019a5568c93941":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b4489d72ec8457cb6a8430ee78e1c3d","placeholder":"​","style":"IPY_MODEL_bd50eb3c39404fbca09451c427755728","value":" 1/1 [00:00&lt;00:00,  8.27it/s]"}},"a3fc6ede35194bc2ae0727e741f062e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"b1f0064c0d33471db85d93efd4ff6afe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4fcceccf52c4855bcf72b90a9452757":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bbc322e566d464a88abdbb96a02ac7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d0489c1b934ceb814ccd09ee0a1b43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b4489d72ec8457cb6a8430ee78e1c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd50eb3c39404fbca09451c427755728":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Yu8CadD_okc"
   },
   "source": [
    "# MCC Aggregates Forecasting - Baseline Models\n",
    "\n",
    "This notebook implements baseline forecasting methods for MCC aggregates:\n",
    "- Seasonal Naïve (multiple seasonalities)\n",
    "- Random Walk\n",
    "- ETS (Exponential Smoothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2755,
     "status": "ok",
     "timestamp": 1748874623486,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "dHh5B2OL_oko",
    "outputId": "7a5146e2-dfa2-4705-f94b-81645a148352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Models for MCC Aggregates Forecasting\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress specific statsmodels warnings\n",
    "import logging\n",
    "logging.getLogger('statsmodels').setLevel(logging.ERROR)\n",
    "\n",
    "print(\"Baseline Models for MCC Aggregates Forecasting\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26266,
     "status": "ok",
     "timestamp": 1748874649735,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "Zw-XUjio_okr",
    "outputId": "9633bbf7-0adc-4cf5-cf5a-49d32ea5b83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n",
      "Environment: colab\n",
      "Base path: /content/drive/MyDrive/fcst\n"
     ]
    }
   ],
   "source": [
    "def detect_environment():\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive/')\n",
    "        return 'colab', '/content/drive/MyDrive/fcst'\n",
    "    except ImportError:\n",
    "        return 'local', '..'\n",
    "\n",
    "environment, base_path = detect_environment()\n",
    "print(f\"Environment: {environment}\")\n",
    "print(f\"Base path: {base_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6628,
     "status": "ok",
     "timestamp": 1748874656340,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "kM0z00JP_oks",
    "outputId": "096f6a66-39cc-4352-a8a4-b445c38596d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Statsmodels ETS imported successfully\n",
      "⚠ Could not import evaluation functions - will create simple evaluation\n"
     ]
    }
   ],
   "source": [
    "# Forecasting libraries\n",
    "try:\n",
    "    from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "    from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "    print(\"✓ Statsmodels ETS imported successfully\")\n",
    "    ETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"⚠ Statsmodels not available - install with: pip install statsmodels\")\n",
    "    ETSModel = None\n",
    "    ExponentialSmoothing = None\n",
    "    ETS_AVAILABLE = False\n",
    "\n",
    "# Import evaluation functions\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append(base_path)\n",
    "    from evaluation import evaluate_and_report_mcc\n",
    "    print(\"✓ Loaded evaluation functions from project\")\n",
    "except ImportError:\n",
    "    print(\"⚠ Could not import evaluation functions - will create simple evaluation\")\n",
    "\n",
    "    def evaluate_and_report_mcc(model_name, y_true, y_pred, y_train, categories, print_report=True):\n",
    "        \"\"\"Simple evaluation function fallback\"\"\"\n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "        # Simple sMAPE calculation\n",
    "        smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
    "\n",
    "        # Simple RMSSE calculation\n",
    "        naive_error = np.mean(np.abs(np.diff(y_train)))\n",
    "        rmsse = rmse / (naive_error + 1e-8)\n",
    "\n",
    "        metrics = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'sMAPE_w': smape,\n",
    "            'RMSSE_w': rmsse\n",
    "        }\n",
    "\n",
    "        if print_report:\n",
    "            print(f\"\\n=== {model_name} Results ===\")\n",
    "            print(f\"MAE: {mae:.4f}\")\n",
    "            print(f\"RMSE: {rmse:.4f}\")\n",
    "            print(f\"sMAPE: {smape:.2f}%\")\n",
    "            print(f\"RMSSE: {rmsse:.4f}\")\n",
    "\n",
    "        return metrics, f\"{model_name} evaluation completed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8670,
     "status": "ok",
     "timestamp": 1748874665012,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "40xJV170_oku",
    "outputId": "0294d562-07c2-44bb-bdbb-7ea7f1fbdd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading baseline features dataset...\n",
      "✓ Loaded parquet file\n",
      "Total rows: 2298956\n",
      "Unique series: 6026\n",
      "Date range: 2009-12-28 00:00:00 to 2019-10-21 00:00:00\n",
      "Train rows: 1836701\n",
      "Test rows: 462255\n",
      "Sampled series: 1000\n",
      "Sampled rows: 382020\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading baseline features dataset...\")\n",
    "\n",
    "# Try parquet first, fallback to CSV\n",
    "baseline_parquet = f'{base_path}/data/features/baseline_statistical_full.parquet'\n",
    "baseline_csv = f'{base_path}/data/features/baseline_statistical_full.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(baseline_parquet)\n",
    "    print(\"✓ Loaded parquet file\")\n",
    "except:\n",
    "    try:\n",
    "        df = pd.read_csv(baseline_csv)\n",
    "        print(\"✓ Loaded CSV file\")\n",
    "    except:\n",
    "        print(\"❌ Could not load baseline statistical files\")\n",
    "        print(\"Please run feature_engineering_final.py first to create the baseline features\")\n",
    "        exit()\n",
    "\n",
    "# Date is already converted to datetime in the parquet file\n",
    "df = df.sort_values(['client_id', 'category', 'date'])\n",
    "\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Unique series: {df.groupby(['client_id', 'category']).ngroups}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Train rows: {(df['split'] == 'train').sum()}\")\n",
    "print(f\"Test rows: {(df['split'] == 'test').sum()}\")\n",
    "\n",
    "# Sample 1000 time series\n",
    "np.random.seed(42)\n",
    "series_ids = df.groupby(['client_id', 'category']).size().reset_index()\n",
    "series_ids = series_ids.sample(n=min(1000, len(series_ids)), random_state=42)\n",
    "\n",
    "# Filter data to selected series\n",
    "df_sample = df.merge(series_ids[['client_id', 'category']], on=['client_id', 'category'])\n",
    "print(f\"Sampled series: {len(series_ids)}\")\n",
    "print(f\"Sampled rows: {len(df_sample)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2083,
     "status": "ok",
     "timestamp": 1748874667104,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "r46u3nL9_okz",
    "outputId": "5440d77f-fdd7-457a-aad6-369afb6327fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series ready for forecasting: 1000\n"
     ]
    }
   ],
   "source": [
    "def prepare_series_data(df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Prepare time series data for forecasting using existing split column.\"\"\"\n",
    "    series_data = {}\n",
    "\n",
    "    for (client_id, category), group in df.groupby(['client_id', 'category']):\n",
    "        group = group.sort_values('date')\n",
    "\n",
    "        # Use existing split column\n",
    "        train_group = group[group['split'] == 'train']\n",
    "        test_group = group[group['split'] == 'test']\n",
    "\n",
    "        # Ensure we have enough data (at least 30 weeks of training data)\n",
    "        if len(train_group) >= 30 and len(test_group) > 0:\n",
    "            series_key = f\"{client_id}_{category}\"\n",
    "\n",
    "            train_data = train_group['amount'].values\n",
    "            test_data = test_group['amount'].values\n",
    "            dates = group['date'].values\n",
    "\n",
    "            series_data[series_key] = {\n",
    "                'train': train_data,\n",
    "                'test': test_data,\n",
    "                'dates': dates,\n",
    "                'category': category,\n",
    "                'client_id': client_id,\n",
    "                'split_idx': len(train_data)\n",
    "            }\n",
    "\n",
    "    return series_data\n",
    "\n",
    "series_data = prepare_series_data(df_sample)\n",
    "print(f\"Series ready for forecasting: {len(series_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1748874667115,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "JssNYvuU_okz"
   },
   "outputs": [],
   "source": [
    "\n",
    "class SeasonalNaive:\n",
    "    \"\"\"Seasonal Naïve forecasting model.\"\"\"\n",
    "\n",
    "    def __init__(self, season_length: int):\n",
    "        self.season_length = season_length\n",
    "\n",
    "    def fit(self, y: np.ndarray):\n",
    "        self.y_train = y\n",
    "        return self\n",
    "\n",
    "    def forecast(self, steps: int) -> np.ndarray:\n",
    "        if len(self.y_train) < self.season_length:\n",
    "            # If not enough data, use simple naive\n",
    "            return np.full(steps, self.y_train[-1])\n",
    "\n",
    "        # Repeat seasonal pattern\n",
    "        seasonal_pattern = self.y_train[-self.season_length:]\n",
    "        forecasts = []\n",
    "\n",
    "        for i in range(steps):\n",
    "            forecasts.append(seasonal_pattern[i % self.season_length])\n",
    "\n",
    "        return np.array(forecasts)\n",
    "\n",
    "class RandomWalk:\n",
    "    \"\"\"Random Walk forecasting model.\"\"\"\n",
    "\n",
    "    def fit(self, y: np.ndarray):\n",
    "        self.last_value = y[-1]\n",
    "        return self\n",
    "\n",
    "    def forecast(self, steps: int) -> np.ndarray:\n",
    "        return np.full(steps, self.last_value)\n",
    "\n",
    "if ETS_AVAILABLE:\n",
    "    class ETSWrapper:\n",
    "        \"\"\"Improved ETS (Exponential Smoothing) wrapper with better error handling.\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            self.model = None\n",
    "            self.fallback_value = None\n",
    "\n",
    "        def fit(self, y: np.ndarray):\n",
    "            self.fallback_value = y[-1]\n",
    "\n",
    "            # Clean the data\n",
    "            y_clean = np.array(y)\n",
    "            y_clean = y_clean[~np.isnan(y_clean)]\n",
    "            y_clean = y_clean[np.isfinite(y_clean)]\n",
    "\n",
    "            if len(y_clean) < 10:\n",
    "                return self\n",
    "\n",
    "            # Try multiple ETS configurations in order of preference\n",
    "            configs = [\n",
    "                # Simple exponential smoothing\n",
    "                {'error': 'add', 'trend': None, 'seasonal': None},\n",
    "                # Linear trend\n",
    "                {'error': 'add', 'trend': 'add', 'seasonal': None},\n",
    "                # With seasonality (if enough data)\n",
    "                {'error': 'add', 'trend': 'add', 'seasonal': 'add', 'seasonal_periods': min(52, len(y_clean)//3)} if len(y_clean) >= 104 else None,\n",
    "                # Multiplicative error\n",
    "                {'error': 'mul', 'trend': 'add', 'seasonal': None} if np.all(y_clean > 0) else None,\n",
    "            ]\n",
    "\n",
    "            # Filter out None configs\n",
    "            configs = [c for c in configs if c is not None]\n",
    "\n",
    "            for config in configs:\n",
    "                try:\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "                        # Try new ETS implementation first\n",
    "                        if 'seasonal_periods' in config:\n",
    "                            self.model = ETSModel(y_clean, **config).fit(disp=False)\n",
    "                        else:\n",
    "                            # Use Holt-Winters for simpler models (more stable)\n",
    "                            hw_config = {\n",
    "                                'trend': config.get('trend'),\n",
    "                                'seasonal': config.get('seasonal'),\n",
    "                                'seasonal_periods': config.get('seasonal_periods', 52)\n",
    "                            }\n",
    "                            self.model = ExponentialSmoothing(y_clean, **hw_config).fit(optimized=True)\n",
    "\n",
    "                        # Test if model can forecast\n",
    "                        _ = self.model.forecast(1)\n",
    "                        break\n",
    "\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            return self\n",
    "\n",
    "        def forecast(self, steps: int) -> np.ndarray:\n",
    "            if self.model is None:\n",
    "                return np.full(steps, self.fallback_value)\n",
    "\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    forecast = self.model.forecast(steps)\n",
    "\n",
    "                    # Handle any invalid forecasts\n",
    "                    forecast = np.array(forecast)\n",
    "                    forecast = np.where(np.isfinite(forecast), forecast, self.fallback_value)\n",
    "\n",
    "                    return forecast\n",
    "\n",
    "            except Exception:\n",
    "                return np.full(steps, self.fallback_value)\n",
    "else:\n",
    "    # Simple fallback ETS if statsmodels not available\n",
    "    class ETSWrapper:\n",
    "        \"\"\"Simple ETS fallback using exponential smoothing.\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            self.alpha = 0.3\n",
    "            self.last_value = None\n",
    "\n",
    "        def fit(self, y: np.ndarray):\n",
    "            self.last_value = y[-1]\n",
    "            # Simple exponential smoothing\n",
    "            smoothed = y[0]\n",
    "            for val in y[1:]:\n",
    "                smoothed = self.alpha * val + (1 - self.alpha) * smoothed\n",
    "            self.last_value = smoothed\n",
    "            return self\n",
    "\n",
    "        def forecast(self, steps: int) -> np.ndarray:\n",
    "            return np.full(steps, self.last_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9254,
     "status": "ok",
     "timestamp": 1748874676373,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "4FhWm_rY_ok0",
    "outputId": "e4202889-9e46-413f-ca33-7a91481b59c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Random_Walk...\n",
      "Successful forecasts: 1000\n",
      "\n",
      "Running ETS...\n",
      "Successful forecasts: 1000\n",
      "\n",
      "Running Seasonal_Naive_4...\n",
      "Successful forecasts: 1000\n",
      "\n",
      "Running Seasonal_Naive_8...\n",
      "Successful forecasts: 1000\n",
      "\n",
      "Running Seasonal_Naive_12...\n",
      "Successful forecasts: 1000\n",
      "\n",
      "Running Seasonal_Naive_36...\n",
      "Successful forecasts: 1000\n",
      "\n",
      "Running Seasonal_Naive_52...\n",
      "Successful forecasts: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_forecasting_experiment(series_data: Dict, models: Dict) -> Dict:\n",
    "    \"\"\"Run forecasting experiment on all series.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model_class in models.items():\n",
    "        print(f\"\\nRunning {model_name}...\")\n",
    "\n",
    "        all_y_true = []\n",
    "        all_y_pred = []\n",
    "        all_y_train = []\n",
    "        all_categories = []\n",
    "\n",
    "        successful_forecasts = 0\n",
    "        failed_forecasts = 0\n",
    "\n",
    "        for series_key, data in series_data.items():\n",
    "            try:\n",
    "                train = data['train']\n",
    "                test = data['test']\n",
    "\n",
    "                # Skip if train data is too short\n",
    "                if len(train) < 10:\n",
    "                    continue\n",
    "\n",
    "                # Fit model\n",
    "                if isinstance(model_class, dict):  # Seasonal naive with different seasons\n",
    "                    season_length = model_class['season_length']\n",
    "                    model = SeasonalNaive(season_length)\n",
    "                else:\n",
    "                    model = model_class()\n",
    "\n",
    "                model.fit(train)\n",
    "\n",
    "                # Forecast\n",
    "                forecast = model.forecast(len(test))\n",
    "\n",
    "                # Validate forecast\n",
    "                if len(forecast) == len(test) and np.all(np.isfinite(forecast)):\n",
    "                    # Store results\n",
    "                    all_y_true.extend(test)\n",
    "                    all_y_pred.extend(forecast)\n",
    "                    all_y_train.extend(train)\n",
    "                    all_categories.extend([data['category']] * len(test))\n",
    "\n",
    "                    successful_forecasts += 1\n",
    "                else:\n",
    "                    failed_forecasts += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                failed_forecasts += 1\n",
    "                continue\n",
    "\n",
    "        if successful_forecasts > 0:\n",
    "            results[model_name] = {\n",
    "                'y_true': np.array(all_y_true),\n",
    "                'y_pred': np.array(all_y_pred),\n",
    "                'y_train': np.array(all_y_train),\n",
    "                'categories': np.array(all_categories),\n",
    "                'successful_forecasts': successful_forecasts,\n",
    "                'failed_forecasts': failed_forecasts\n",
    "            }\n",
    "            print(f\"Successful forecasts: {successful_forecasts}\")\n",
    "            if failed_forecasts > 0:\n",
    "                print(f\"Failed forecasts: {failed_forecasts}\")\n",
    "        else:\n",
    "            print(f\"No successful forecasts for {model_name}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Random_Walk': RandomWalk,\n",
    "    'ETS': ETSWrapper,\n",
    "    'Seasonal_Naive_4': {'season_length': 4},\n",
    "    'Seasonal_Naive_8': {'season_length': 8},\n",
    "    'Seasonal_Naive_12': {'season_length': 12},\n",
    "    'Seasonal_Naive_36': {'season_length': 36},\n",
    "    'Seasonal_Naive_52': {'season_length': 52}\n",
    "}\n",
    "\n",
    "# Run experiments\n",
    "forecast_results = run_forecasting_experiment(series_data, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1748874676968,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "3oeqIh7s_ok1",
    "outputId": "764aa11e-5bb8-4cd4-ed54-e47c17cbc25b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING: Random_Walk\n",
      "============================================================\n",
      "\n",
      "=== Random_Walk Results ===\n",
      "MAE: 129.1289\n",
      "RMSE: 203.6583\n",
      "sMAPE: 81.28%\n",
      "RMSSE: 2.4221\n",
      "\n",
      "============================================================\n",
      "EVALUATING: ETS\n",
      "============================================================\n",
      "\n",
      "=== ETS Results ===\n",
      "MAE: 101.1567\n",
      "RMSE: 155.8964\n",
      "sMAPE: 68.41%\n",
      "RMSSE: 1.8541\n",
      "\n",
      "============================================================\n",
      "EVALUATING: Seasonal_Naive_4\n",
      "============================================================\n",
      "\n",
      "=== Seasonal_Naive_4 Results ===\n",
      "MAE: 132.6081\n",
      "RMSE: 213.2287\n",
      "sMAPE: 81.38%\n",
      "RMSSE: 2.5360\n",
      "\n",
      "============================================================\n",
      "EVALUATING: Seasonal_Naive_8\n",
      "============================================================\n",
      "\n",
      "=== Seasonal_Naive_8 Results ===\n",
      "MAE: 135.0889\n",
      "RMSE: 228.3745\n",
      "sMAPE: 81.86%\n",
      "RMSSE: 2.7161\n",
      "\n",
      "============================================================\n",
      "EVALUATING: Seasonal_Naive_12\n",
      "============================================================\n",
      "\n",
      "=== Seasonal_Naive_12 Results ===\n",
      "MAE: 135.7624\n",
      "RMSE: 224.1679\n",
      "sMAPE: 81.78%\n",
      "RMSSE: 2.6661\n",
      "\n",
      "============================================================\n",
      "EVALUATING: Seasonal_Naive_36\n",
      "============================================================\n",
      "\n",
      "=== Seasonal_Naive_36 Results ===\n",
      "MAE: 135.4675\n",
      "RMSE: 219.8807\n",
      "sMAPE: 81.68%\n",
      "RMSSE: 2.6151\n",
      "\n",
      "============================================================\n",
      "EVALUATING: Seasonal_Naive_52\n",
      "============================================================\n",
      "\n",
      "=== Seasonal_Naive_52 Results ===\n",
      "MAE: 135.1183\n",
      "RMSE: 219.0510\n",
      "sMAPE: 81.46%\n",
      "RMSSE: 2.6052\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_all_models(forecast_results: Dict) -> Dict:\n",
    "    \"\"\"Evaluate all models and generate reports.\"\"\"\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for model_name, results in forecast_results.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"EVALUATING: {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Use a representative training series for RMSSE calculation\n",
    "        y_train_sample = results['y_train'][:min(len(results['y_train']), 1000)]\n",
    "\n",
    "        overall_metrics, report = evaluate_and_report_mcc(\n",
    "            model_name=model_name,\n",
    "            y_true=results['y_true'],\n",
    "            y_pred=results['y_pred'],\n",
    "            y_train=y_train_sample,\n",
    "            categories=results['categories'],\n",
    "            print_report=True\n",
    "        )\n",
    "\n",
    "        evaluation_results[model_name] = {\n",
    "            'overall_metrics': overall_metrics,\n",
    "            'report': report,\n",
    "            'successful_forecasts': results['successful_forecasts'],\n",
    "            'failed_forecasts': results.get('failed_forecasts', 0)\n",
    "        }\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_all_models(forecast_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1748874677537,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "1MD7zjxv_ok5",
    "outputId": "bf2380f7-1ff6-4bf4-a82f-9dcf91ba3ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: /content/drive/MyDrive/fcst/MCC Aggregates Forecasting/Baseline models/baseline_results.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_results_to_json(evaluation_results: Dict, filename: str = 'baseline_results.json'):\n",
    "    \"\"\"Save evaluation results to JSON file.\"\"\"\n",
    "\n",
    "    def convert_numpy_types(obj):\n",
    "        \"\"\"Convert numpy types to Python native types for JSON serialization.\"\"\"\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_numpy_types(item) for item in obj]\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    # Prepare results for JSON serialization\n",
    "    json_results = {}\n",
    "\n",
    "    # Add all models as individual entries\n",
    "    json_results['models'] = {}\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        json_results['models'][model_name] = {\n",
    "            'overall_metrics': convert_numpy_types(results['overall_metrics']),\n",
    "            'successful_forecasts': results['successful_forecasts'],\n",
    "            'failed_forecasts': results.get('failed_forecasts', 0),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "    # Add metadata\n",
    "    json_results['metadata'] = {\n",
    "        'environment': environment,\n",
    "        'total_series_sampled': len(series_data),\n",
    "        'evaluation_date': datetime.now().isoformat(),\n",
    "        'dataset_source': 'data/features/baseline_statistical_full.parquet',\n",
    "        'train_test_split': 'predefined_split',\n",
    "        'models_evaluated': list(evaluation_results.keys()),\n",
    "        'ets_available': ETS_AVAILABLE,\n",
    "        'warning_handling': 'Improved ETS with multiple fallback configurations'\n",
    "    }\n",
    "\n",
    "    # Save to file\n",
    "    output_file = f'{base_path}/MCC Aggregates Forecasting/Baseline models/{filename}'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(json_results, f, indent=2)\n",
    "\n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    return json_results\n",
    "\n",
    "# Save results\n",
    "final_results = save_results_to_json(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1748874677756,
     "user": {
      "displayName": "V L",
      "userId": "06129047709976680873"
     },
     "user_tz": -180
    },
    "id": "dUD5m4PC_ok5",
    "outputId": "6763a63f-5cd6-480f-8a68-9dd240bb3d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BASELINE MODELS EXPERIMENT SUMMARY\n",
      "================================================================================\n",
      "Environment: colab\n",
      "Total series processed: 1000\n",
      "Models evaluated: 7\n",
      "ETS available: True\n",
      "\n",
      "==================================================\n",
      "ALL MODELS PERFORMANCE (by sMAPE_w):\n",
      "==================================================\n",
      "Random_Walk: 81.2765\n",
      "ETS: 68.4099\n",
      "Seasonal_Naive_4: 81.3838\n",
      "Seasonal_Naive_8: 81.8587\n",
      "Seasonal_Naive_12: 81.7820\n",
      "Seasonal_Naive_36: 81.6750\n",
      "Seasonal_Naive_52: 81.4566\n",
      "\n",
      "==================================================\n",
      "OVERALL RANKING (by sMAPE_w):\n",
      "==================================================\n",
      "1. ETS: 68.4099\n",
      "2. Random_Walk: 81.2765\n",
      "3. Seasonal_Naive_4: 81.3838\n",
      "4. Seasonal_Naive_52: 81.4566\n",
      "5. Seasonal_Naive_36: 81.6750\n",
      "6. Seasonal_Naive_12: 81.7820\n",
      "7. Seasonal_Naive_8: 81.8587\n",
      "\n",
      "Results saved to: baseline_results.json\n",
      "Experiment completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BASELINE MODELS EXPERIMENT SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Environment: {environment}\")\n",
    "print(f\"Total series processed: {len(series_data)}\")\n",
    "print(f\"Models evaluated: {len(evaluation_results)}\")\n",
    "print(f\"ETS available: {ETS_AVAILABLE}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ALL MODELS PERFORMANCE (by sMAPE_w):\")\n",
    "print(\"=\"*50)\n",
    "all_scores = {}\n",
    "for model_name, results in evaluation_results.items():\n",
    "    if 'sMAPE_w' in results['overall_metrics']:\n",
    "        all_scores[model_name] = results['overall_metrics']['sMAPE_w']\n",
    "        print(f\"{model_name}: {results['overall_metrics']['sMAPE_w']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OVERALL RANKING (by sMAPE_w):\")\n",
    "print(\"=\"*50)\n",
    "if all_scores:\n",
    "    sorted_models = sorted(all_scores.items(), key=lambda x: x[1])\n",
    "    for i, (model, score) in enumerate(sorted_models):\n",
    "        print(f\"{i+1}. {model}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nResults saved to: baseline_results.json\")\n",
    "print(\"Experiment completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

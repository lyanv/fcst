{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCC Aggregates Forecasting - Statistical Models\n",
    "\n",
    "Statistical forecasting methods for MCC aggregates:\n",
    "- Prophet (5 strategies with CV selection)\n",
    "- SARIMA (with time limits)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Statistical Models for MCC Aggregates Forecasting\")\n",
    "print(\"=\" * 50)\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def detect_environment():\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive/')\n",
    "        return 'colab', '/content/drive/MyDrive/fcst'\n",
    "    except ImportError:\n",
    "        return 'local', '..'\n",
    "\n",
    "environment, base_path = detect_environment()\n",
    "print(f\"Environment: {environment}\")\n",
    "print(f\"Base path: {base_path}\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Statistical forecasting libraries\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    print(\"\u2713 Prophet imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0 Prophet not available - install with: pip install prophet\")\n",
    "    Prophet = None\n",
    "\n",
    "try:\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    print(\"\u2713 SARIMA/ARIMA imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0 Statsmodels not available - install with: pip install statsmodels\")\n",
    "    SARIMAX = None\n",
    "    ARIMA = None\n",
    "\n",
    "# Import evaluation functions\n",
    "try:\n",
    "    import sys\n",
    "    sys.path.append(base_path)\n",
    "    from evaluation import evaluate_and_report_mcc\n",
    "    print(\"\u2713 Loaded evaluation functions from project\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0 Could not import evaluation functions - will create simple evaluation\")\n",
    "    \n",
    "    def evaluate_and_report_mcc(model_name, y_true, y_pred, y_train, categories, print_report=True):\n",
    "        \"\"\"Simple evaluation function fallback\"\"\"\n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "        \n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        \n",
    "        # Simple sMAPE calculation\n",
    "        smape = 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))\n",
    "        \n",
    "        # Simple RMSSE calculation\n",
    "        naive_error = np.mean(np.abs(np.diff(y_train)))\n",
    "        rmsse = rmse / (naive_error + 1e-8)\n",
    "        \n",
    "        metrics = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'sMAPE_w': smape,\n",
    "            'RMSSE_w': rmsse\n",
    "        }\n",
    "        \n",
    "        if print_report:\n",
    "            print(f\"\\n=== {model_name} Results ===\")\n",
    "            print(f\"MAE: {mae:.4f}\")\n",
    "            print(f\"RMSE: {rmse:.4f}\")\n",
    "            print(f\"sMAPE: {smape:.2f}%\")\n",
    "            print(f\"RMSSE: {rmsse:.4f}\")\n",
    "        \n",
    "        return metrics, f\"{model_name} evaluation completed\"\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Loading baseline statistical dataset...\")\n",
    "\n",
    "# Try parquet first, fallback to CSV\n",
    "baseline_parquet = f'{base_path}/data/features/baseline_statistical_full.parquet'\n",
    "baseline_csv = f'{base_path}/data/features/baseline_statistical_full.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(baseline_parquet)\n",
    "    print(\"\u2713 Loaded parquet file\")\n",
    "except:\n",
    "    try:\n",
    "        df = pd.read_csv(baseline_csv)\n",
    "        print(\"\u2713 Loaded CSV file\")\n",
    "    except:\n",
    "        print(\"\u274c Could not load baseline statistical files\")\n",
    "        print(\"Please run feature_engineering_final.py first to create the baseline features\")\n",
    "        exit()\n",
    "\n",
    "# Convert date column and sort\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['client_id', 'category', 'date'])\n",
    "\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Unique series: {df.groupby(['client_id', 'category']).ngroups:,}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Train records: {(df['split'] == 'train').sum():,}\")\n",
    "print(f\"Test records: {(df['split'] == 'test').sum():,}\")\n",
    "\n",
    "# Sample time series with minimum length requirement\n",
    "np.random.seed(42)\n",
    "series_stats = df.groupby(['client_id', 'category']).agg({\n",
    "    'split': 'count',  # total records\n",
    "    'amount': 'count'  # verify same count\n",
    "}).reset_index()\n",
    "series_stats.columns = ['client_id', 'category', 'total_records', 'amount_count']\n",
    "series_ids = series_stats[series_stats['total_records'] >= 104]  # At least 104 weeks\n",
    "\n",
    "# Prophet: 1000 series (fast model)\n",
    "prophet_series = series_ids.sample(n=min(1000, len(series_ids)), random_state=42)\n",
    "df_prophet = df.merge(prophet_series[['client_id', 'category']], on=['client_id', 'category'])\n",
    "\n",
    "# SARIMA: 150 series (slow model)\n",
    "sarima_series = series_ids.sample(n=min(150, len(series_ids)), random_state=123)\n",
    "df_sarima = df.merge(sarima_series[['client_id', 'category']], on=['client_id', 'category'])\n",
    "\n",
    "print(f\"Prophet sample: {len(prophet_series)} series, {len(df_prophet):,} rows\")\n",
    "print(f\"SARIMA sample: {len(sarima_series)} series, {len(df_sarima):,} rows\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def create_train_test_split_from_split_column(df_input):\n",
    "    \"\"\"Use existing split column to create train/test splits\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for (client_id, category), group in df_input.groupby(['client_id', 'category']):\n",
    "        group = group.sort_values('date')\n",
    "        train_data = group[group['split'] == 'train'].copy()\n",
    "        test_data = group[group['split'] == 'test'].copy()\n",
    "        \n",
    "        # Only include series with both train and test data\n",
    "        if len(train_data) > 0 and len(test_data) > 0:\n",
    "            results.append({\n",
    "                'client_id': client_id,\n",
    "                'category': category,\n",
    "                'train_data': train_data,\n",
    "                'test_data': test_data,\n",
    "                'train_size': len(train_data)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "prophet_splits = create_train_test_split_from_split_column(df_prophet)\n",
    "sarima_splits = create_train_test_split_from_split_column(df_sarima)\n",
    "\n",
    "print(f\"Prophet valid splits: {len(prophet_splits)}\")\n",
    "print(f\"SARIMA valid splits: {len(sarima_splits)}\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if Prophet is not None:\n",
    "    def prophet_strategy_1(train_data):\n",
    "        \"\"\"Basic Prophet with weekly seasonality\"\"\"\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            seasonality_mode='multiplicative'\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def prophet_strategy_2(train_data):\n",
    "        \"\"\"Prophet with additional regressors\"\"\"\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            seasonality_mode='additive'\n",
    "        )\n",
    "        model.add_regressor('month')\n",
    "        model.add_regressor('quarter')\n",
    "        return model\n",
    "\n",
    "    def prophet_strategy_3(train_data):\n",
    "        \"\"\"Prophet with custom seasonalities\"\"\"\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=False,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False\n",
    "        )\n",
    "        model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "        model.add_seasonality(name='quarterly', period=91.25, fourier_order=3)\n",
    "        return model\n",
    "\n",
    "    def prophet_strategy_4(train_data):\n",
    "        \"\"\"Prophet with trend changepoints\"\"\"\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            changepoint_prior_scale=0.05,\n",
    "            seasonality_prior_scale=10.0\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def prophet_strategy_5(train_data):\n",
    "        \"\"\"Prophet with holidays and growth\"\"\"\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            growth='linear',\n",
    "            seasonality_mode='multiplicative',\n",
    "            changepoint_prior_scale=0.1\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    prophet_strategies = {\n",
    "        'strategy_1': prophet_strategy_1,\n",
    "        'strategy_2': prophet_strategy_2,\n",
    "        'strategy_3': prophet_strategy_3,\n",
    "        'strategy_4': prophet_strategy_4,\n",
    "        'strategy_5': prophet_strategy_5\n",
    "    }\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    def evaluate_prophet_strategy(strategy_name, strategy_func, splits_sample, max_series=100):\n",
    "        \"\"\"Evaluate Prophet strategy on small CV dataset\"\"\"\n",
    "        print(f\"Evaluating Prophet {strategy_name}...\")\n",
    "        \n",
    "        errors = []\n",
    "        successful_fits = 0\n",
    "        start_total_time = time.time()\n",
    "        \n",
    "        # Use small sample for CV\n",
    "        cv_splits = splits_sample[:max_series]\n",
    "        \n",
    "        for split in cv_splits:\n",
    "            # Check total time limit\n",
    "            if time.time() - start_total_time > 60:\n",
    "                print(f\"  {strategy_name}: Timeout reached after {successful_fits} series\")\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                train_data = split['train_data'].copy()\n",
    "                test_data = split['test_data'].copy()\n",
    "                \n",
    "                # Prepare Prophet format\n",
    "                prophet_train = pd.DataFrame({\n",
    "                    'ds': train_data['date'],\n",
    "                    'y': train_data['amount']\n",
    "                })\n",
    "                \n",
    "                # Add regressors if needed\n",
    "                if strategy_name == 'strategy_2':\n",
    "                    prophet_train['month'] = train_data['month']\n",
    "                    prophet_train['quarter'] = train_data['quarter']\n",
    "                \n",
    "                # Fit model\n",
    "                model = strategy_func(train_data)\n",
    "                model.fit(prophet_train)\n",
    "                \n",
    "                # Make forecast\n",
    "                future = model.make_future_dataframe(periods=len(test_data), freq='W')\n",
    "                if strategy_name == 'strategy_2':\n",
    "                    future['month'] = pd.to_datetime(future['ds']).dt.month\n",
    "                    future['quarter'] = pd.to_datetime(future['ds']).dt.quarter\n",
    "                \n",
    "                forecast = model.predict(future)\n",
    "                predictions = forecast['yhat'].iloc[-len(test_data):].values\n",
    "                \n",
    "                # Calculate error using consistent sMAPE formula\n",
    "                actual = test_data['amount'].values\n",
    "                # Use same sMAPE calculation as in evaluation.py\n",
    "                smape_error = 100 * np.mean(2 * np.abs(predictions - actual) / (np.abs(actual) + np.abs(predictions) + 1e-8))\n",
    "                errors.append(smape_error)\n",
    "                successful_fits += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        avg_error = np.mean(errors) if errors else float('inf')\n",
    "        elapsed_time = time.time() - start_total_time\n",
    "        print(f\"{strategy_name}: {successful_fits}/{len(cv_splits)} successful fits, Avg sMAPE: {avg_error:.2f}%, Time: {elapsed_time:.1f}s\")\n",
    "        \n",
    "        return avg_error, successful_fits\n",
    "\n",
    "    # Run Prophet CV\n",
    "    print(\"Running Prophet Cross-Validation...\")\n",
    "    prophet_cv_results = {}\n",
    "\n",
    "    for strategy_name, strategy_func in prophet_strategies.items():\n",
    "        error, fits = evaluate_prophet_strategy(strategy_name, strategy_func, prophet_splits)\n",
    "        prophet_cv_results[strategy_name] = {'error': error, 'fits': fits}\n",
    "\n",
    "    # Select best Prophet strategy\n",
    "    best_prophet = min(prophet_cv_results.keys(), key=lambda x: prophet_cv_results[x]['error'])\n",
    "    print(f\"\\nBest Prophet strategy: {best_prophet} (sMAPE: {prophet_cv_results[best_prophet]['error']:.2f}%)\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "    def fit_prophet_model(train_data, strategy_name):\n",
    "        \"\"\"Fit Prophet model with selected strategy\"\"\"\n",
    "        prophet_train = pd.DataFrame({\n",
    "            'ds': train_data['date'],\n",
    "            'y': train_data['amount']\n",
    "        })\n",
    "        \n",
    "        if strategy_name == 'strategy_2':\n",
    "            prophet_train['month'] = train_data['month']\n",
    "            prophet_train['quarter'] = train_data['quarter']\n",
    "        \n",
    "        model = prophet_strategies[strategy_name](train_data)\n",
    "        model.fit(prophet_train)\n",
    "        return model\n",
    "\n",
    "    print(f\"\\nRunning Prophet final evaluation with {best_prophet}...\")\n",
    "    prophet_results = []\n",
    "    prophet_predictions = []\n",
    "    prophet_actuals = []\n",
    "    prophet_categories = []\n",
    "\n",
    "    # Use 500 series for final evaluation\n",
    "    eval_splits = prophet_splits[:500]\n",
    "    start_prophet_time = time.time()\n",
    "\n",
    "    for i, split in enumerate(eval_splits):\n",
    "        # Check total time limit\n",
    "        if time.time() - start_prophet_time > 60:\n",
    "            print(f\"Prophet: Timeout reached after {i} series\")\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            train_data = split['train_data']\n",
    "            test_data = split['test_data']\n",
    "            \n",
    "            # Fit model\n",
    "            model = fit_prophet_model(train_data, best_prophet)\n",
    "            \n",
    "            # Forecast\n",
    "            future = model.make_future_dataframe(periods=len(test_data), freq='W')\n",
    "            if best_prophet == 'strategy_2':\n",
    "                future['month'] = pd.to_datetime(future['ds']).dt.month\n",
    "                future['quarter'] = pd.to_datetime(future['ds']).dt.quarter\n",
    "            \n",
    "            forecast = model.predict(future)\n",
    "            predictions = forecast['yhat'].iloc[-len(test_data):].values\n",
    "            \n",
    "            # Store results\n",
    "            actual = test_data['amount'].values\n",
    "            prophet_predictions.extend(predictions)\n",
    "            prophet_actuals.extend(actual)\n",
    "            prophet_categories.extend([split['category']] * len(actual))\n",
    "            \n",
    "            if (i + 1) % 50 == 0:\n",
    "                elapsed = time.time() - start_prophet_time\n",
    "                print(f\"Prophet: Processed {i+1}/{len(eval_splits)} series ({elapsed:.1f}s)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Prophet error on series {i+1}: {str(e)[:50]}\")\n",
    "            continue\n",
    "\n",
    "    prophet_total_time = time.time() - start_prophet_time\n",
    "    print(f\"Prophet completed: {len(prophet_predictions)} predictions in {prophet_total_time:.1f}s\")\n",
    "\n",
    "else:\n",
    "    print(\"Prophet not available - skipping Prophet evaluation\")\n",
    "    prophet_predictions = []\n",
    "    prophet_actuals = []\n",
    "    prophet_categories = []\n",
    "    prophet_total_time = 0\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if SARIMAX is not None and ARIMA is not None:\n",
    "    def fit_sarima_model(train_data):\n",
    "        \"\"\"Fit SARIMA model\"\"\"\n",
    "        y = train_data['amount'].values\n",
    "        \n",
    "        # Simple SARIMA configuration\n",
    "        try:\n",
    "            # Try SARIMA(1,1,1)(1,1,1,52) first\n",
    "            model = SARIMAX(y, order=(1,1,1), seasonal_order=(1,1,1,52))\n",
    "            fitted_model = model.fit(disp=False, maxiter=50)\n",
    "            return fitted_model\n",
    "            \n",
    "        except:\n",
    "            try:\n",
    "                # Fallback to simpler ARIMA\n",
    "                model = ARIMA(y, order=(1,1,1))\n",
    "                fitted_model = model.fit()\n",
    "                return fitted_model\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    print(\"Running SARIMA evaluation...\")\n",
    "    sarima_predictions = []\n",
    "    sarima_actuals = []\n",
    "    sarima_categories = []\n",
    "    sarima_timeouts = 0\n",
    "    start_sarima_time = time.time()\n",
    "\n",
    "    for i, split in enumerate(sarima_splits):\n",
    "        # Check total time limit\n",
    "        if time.time() - start_sarima_time > 60:\n",
    "            print(f\"SARIMA: Timeout reached after {i} series\")\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            train_data = split['train_data']\n",
    "            test_data = split['test_data']\n",
    "            \n",
    "            # Fit SARIMA\n",
    "            model = fit_sarima_model(train_data)\n",
    "            \n",
    "            if model is None:\n",
    "                sarima_timeouts += 1\n",
    "                print(f\"SARIMA error on series {i+1}\")\n",
    "                continue\n",
    "            \n",
    "            # Forecast\n",
    "            forecast = model.forecast(steps=len(test_data))\n",
    "            predictions = forecast if hasattr(forecast, '__len__') else [forecast] * len(test_data)\n",
    "            \n",
    "            # Store results\n",
    "            actual = test_data['amount'].values\n",
    "            sarima_predictions.extend(predictions[:len(actual)])\n",
    "            sarima_actuals.extend(actual)\n",
    "            sarima_categories.extend([split['category']] * len(actual))\n",
    "            \n",
    "            if (i + 1) % 25 == 0:\n",
    "                elapsed = time.time() - start_sarima_time\n",
    "                print(f\"SARIMA: Processed {i+1}/{len(sarima_splits)} series ({elapsed:.1f}s)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"SARIMA error on series {i+1}: {str(e)[:50]}\")\n",
    "            continue\n",
    "\n",
    "    sarima_total_time = time.time() - start_sarima_time\n",
    "    print(f\"SARIMA completed: {len(sarima_predictions)} predictions, {sarima_timeouts} errors in {sarima_total_time:.1f}s\")\n",
    "\n",
    "    # Mark as inappropriate if too slow\n",
    "    if sarima_total_time > 60:\n",
    "        print(\"WARNING: SARIMA marked as inappropriate due to slow performance\")\n",
    "\n",
    "else:\n",
    "    print(\"SARIMA/ARIMA not available - skipping SARIMA evaluation\")\n",
    "    sarima_predictions = []\n",
    "    sarima_actuals = []\n",
    "    sarima_categories = []\n",
    "    sarima_total_time = 0\n",
    "    sarima_timeouts = 0\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results = {}\n",
    "\n",
    "# Prophet evaluation\n",
    "if prophet_predictions and prophet_total_time <= 60:\n",
    "    # Correctly gather training data only from series that were actually evaluated\n",
    "    prophet_train_data = []\n",
    "    series_count = 0\n",
    "    for i, split in enumerate(eval_splits):\n",
    "        if series_count * 4 >= len(prophet_predictions):\n",
    "            break\n",
    "        prophet_train_data.append(split['train_data']['amount'].values)\n",
    "        series_count += 1\n",
    "    \n",
    "    prophet_train_data = np.concatenate(prophet_train_data)\n",
    "    \n",
    "    prophet_metrics, prophet_report = evaluate_and_report_mcc(\n",
    "        f\"Prophet ({best_prophet})\",\n",
    "        np.array(prophet_actuals),\n",
    "        np.array(prophet_predictions),\n",
    "        prophet_train_data,\n",
    "        np.array(prophet_categories),\n",
    "        print_report=True\n",
    "    )\n",
    "    results['prophet'] = prophet_metrics\n",
    "elif prophet_total_time > 60:\n",
    "    print(\"Prophet excluded from metrics due to timeout (>60s)\")\n",
    "\n",
    "# SARIMA evaluation\n",
    "if sarima_predictions and sarima_total_time <= 60:\n",
    "    # Correctly gather training data only from series that were actually evaluated\n",
    "    sarima_train_data = []\n",
    "    series_count = 0\n",
    "    for i, split in enumerate(sarima_splits):\n",
    "        if series_count * 4 >= len(sarima_predictions):\n",
    "            break\n",
    "        sarima_train_data.append(split['train_data']['amount'].values)\n",
    "        series_count += 1\n",
    "    \n",
    "    sarima_train_data = np.concatenate(sarima_train_data)\n",
    "    \n",
    "    sarima_metrics, sarima_report = evaluate_and_report_mcc(\n",
    "        \"SARIMA\",\n",
    "        np.array(sarima_actuals),\n",
    "        np.array(sarima_predictions),\n",
    "        sarima_train_data,\n",
    "        np.array(sarima_categories),\n",
    "        print_report=True\n",
    "    )\n",
    "    results['sarima'] = sarima_metrics\n",
    "elif sarima_total_time > 60:\n",
    "    print(\"SARIMA excluded from metrics due to timeout (>60s)\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\nSaving results...\")\n",
    "\n",
    "# Prophet strategy details\n",
    "prophet_strategy_details = {\n",
    "    'strategy_1': 'Basic Prophet with weekly/yearly seasonality (multiplicative)',\n",
    "    'strategy_2': 'Prophet with additional regressors (month, quarter) (additive)',\n",
    "    'strategy_3': 'Prophet with custom seasonalities (monthly, quarterly)',\n",
    "    'strategy_4': 'Prophet with trend changepoints (changepoint_prior_scale=0.05)',\n",
    "    'strategy_5': 'Prophet with holidays and growth (multiplicative, changepoint_prior_scale=0.1)'\n",
    "}\n",
    "\n",
    "# Add model info\n",
    "results['model_info'] = {\n",
    "    'environment': environment,\n",
    "    'prophet_available': Prophet is not None,\n",
    "    'sarima_available': SARIMAX is not None and ARIMA is not None,\n",
    "    'evaluation_date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "if Prophet is not None:\n",
    "    results['model_info'].update({\n",
    "        'prophet_strategy': best_prophet,\n",
    "        'prophet_strategy_description': prophet_strategy_details[best_prophet],\n",
    "        'prophet_cv_results': prophet_cv_results,\n",
    "        'prophet_series_evaluated': len([s for s in eval_splits if len(prophet_predictions) > 0]),\n",
    "        'prophet_predictions': len(prophet_predictions),\n",
    "        'prophet_time': prophet_total_time,\n",
    "        'prophet_appropriate': prophet_total_time <= 60,\n",
    "    })\n",
    "\n",
    "if SARIMAX is not None and ARIMA is not None:\n",
    "    results['model_info'].update({\n",
    "        'sarima_series_evaluated': len([s for s in sarima_splits if len(sarima_predictions) > 0]),\n",
    "        'sarima_predictions': len(sarima_predictions),\n",
    "        'sarima_time': sarima_total_time,\n",
    "        'sarima_timeouts': sarima_timeouts,\n",
    "        'sarima_appropriate': sarima_total_time <= 60,\n",
    "    })\n",
    "\n",
    "# Save to JSON\n",
    "output_file = f'{base_path}/MCC Aggregates Forecasting/Statistical models/statistical_models_results.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")\n",
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL MODELS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if Prophet is not None:\n",
    "    print(f\"Prophet Strategy Selection:\")\n",
    "    print(f\"Winner: {best_prophet} - {prophet_strategy_details[best_prophet]}\")\n",
    "    print(f\"CV Results:\")\n",
    "    for strategy, result in prophet_cv_results.items():\n",
    "        print(f\"  {strategy}: sMAPE {result['error']:.2f}%, Fits: {result['fits']}\")\n",
    "\n",
    "    if 'prophet' in results:\n",
    "        print(f\"\\nProphet ({best_prophet}) - APPROPRIATE:\")\n",
    "        print(f\"  - Series evaluated: {results['model_info']['prophet_series_evaluated']}\")\n",
    "        print(f\"  - Predictions made: {len(prophet_predictions)}\")\n",
    "        print(f\"  - Total time: {prophet_total_time:.1f}s\")\n",
    "        print(f\"  - sMAPE: {results['prophet']['sMAPE_w']:.2f}%\")\n",
    "        print(f\"  - RMSSE: {results['prophet']['RMSSE_w']:.4f}\")\n",
    "    elif prophet_total_time > 60:\n",
    "        print(f\"\\nProphet ({best_prophet}) - INAPPROPRIATE (>{prophet_total_time:.1f}s)\")\n",
    "else:\n",
    "    print(\"Prophet not available\")\n",
    "\n",
    "if SARIMAX is not None and ARIMA is not None:\n",
    "    if 'sarima' in results:\n",
    "        print(f\"\\nSARIMA - APPROPRIATE:\")\n",
    "        print(f\"  - Series evaluated: {results['model_info']['sarima_series_evaluated']}\")\n",
    "        print(f\"  - Predictions made: {len(sarima_predictions)}\")\n",
    "        print(f\"  - Total time: {sarima_total_time:.1f}s\")\n",
    "        print(f\"  - Errors: {sarima_timeouts}\")\n",
    "        print(f\"  - sMAPE: {results['sarima']['sMAPE_w']:.2f}%\")\n",
    "        print(f\"  - RMSSE: {results['sarima']['RMSSE_w']:.4f}\")\n",
    "    elif sarima_total_time > 60:\n",
    "        print(f\"\\nSARIMA - INAPPROPRIATE (>{sarima_total_time:.1f}s)\")\n",
    "else:\n",
    "    print(\"SARIMA not available\")\n",
    "\n",
    "print(f\"\\nEnvironment: {environment}\")\n",
    "print(\"Statistical models evaluation completed!\") "
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}